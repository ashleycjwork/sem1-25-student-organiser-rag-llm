[
    {
        "title": "Content from RCP0032 Intake 10 Student Internship Summary Reports",
        "content": "RCP#0032 Intake 10 Student Internship Summary reports  Table of Contents                            Link to Intake 9 Summary Report  RCP#0016 Intake 9 Student Internship Summary reports.pdf that can be used as an example.   AIVE Student Project Interns:  Si Yang (Sean) Chen, Chun-Tung (Chloe) Tsai, Jiawen Deng High-Level Domain work During the first 4-5 weeks, we learned about and tried to understand the AIVE workflow for converting 2D cell image stacks into 3D models and familiarised ourselves with software tools used in the workflow such as ImageJ, MIB and WEKA. Our in-depth understanding was presented in the whiteboard presentation, which detailed key stages in AIVE\u2019s workflow. The team also developed high-level flowcharts showing the entire process and the interconnected stages. Subsequently, we decided to work on the organelle segmentation stage. We converted two ImageJ macros (macros 1 and 1b) from ImageJ Macro Language into Python code for better reproducibility. Building on the public wiki created by previous interns, we added technical documentation and additional notes for both our and previous features, including detailed explanations and flowcharts, to help future interns and people without prior knowledge understand AIVE more easily.    Architecture / Algorithm work  Macro 1:              Macro 1b:  \nTechnical work Macro 1: Image stack is loaded into program and all unique pixel values in entire stack are computed. These pixel values are used as thresholds, which are applied to each image slice in stack to create stacks of binary masks. The mask stack is saved and this is repeated for each threshold.  Macro 1b: The process starts by selecting the input image file (HeLa.tiff) and specifying the output directory. A Gaussian blur is then applied with an XYZ radius of X = 3, Y = 3, and Z = 1, chosen to account for the anisotropic voxel dimensions (3 nm in X and Y, 10 nm in Z). These values ensure consistent blurring across the real-world voxel sizes. Users may need to adjust blur parameters or consider kernel size for different datasets. The macro then processes the entire image stack, saving the results in new stacks.  Key Links \u2022 Whiteboard Presentation: Whiteboard presentation flowchart \u2022 Final Presentation: Final Presentation slides \u2022 Public GitHub: https://github.com/MitochondRuna/AIVE-Intro/wiki \u2022 Python Macros Link: https://github.com/MitochondRuna/AIVE-Intro/ImageJ macros \u2022 Personal Technical Notes: Technical Notes  Clinical Dashboards Student Project Interns: Kathleen Wongso, Jane Xu, Lucas Valente, Yixin Jiang  High-Level Domain work REDCap / Simulacrum Aspect: One of our goals for this aspect of the project was to make use of a larger and more complex dataset (i.e. Simulacrum) than the previous intake used. We aimed to upload as much of the Simulacrum V2 data as we could to REDCap, which shaped how we cleaned our dataset. We also wanted to see if we would break REDCap with the new, larger dataset.   Security Aspect: x  Architecture / Algorithm work  The structure of this project is demonstrated by the following flow chart:  REDCap / Simulacrum Aspect:  1. Cleaned Simulacrum V2 data a. Fixed column names (lowercased all field variable names and added underscores due to REDCap guidelines for field names) b. Identified invalid records \u2022 Assumed \u2018gender_patient\u2019 was based on sex assigned at birth ->  records of female patients with prostate cancer & male patients with gynaecological cancer \u2022 Records where treatment (radiotherapy and chemotherapy /hormonal therapy) occurs after death of patient \u2022 Patients that died before treatment / diagnosis \u2022 Treatments that occurred before tumour diagnosis c. Removed invalid records across the different tables  2. Defined a data dictionary for REDCap a. Defined the instruments: Av Patient, Av Tumour, Av Gene, Sact Regimen Outcome, Sact Cycle, Sact Drug, Rtds (each is a separate table) b. Defined repeating instruments (number of treatments and tumours varied across the patients) c. Defined valid field value types for certain field variables (e.g. \u2018gleason_combined\u2019 in av_tumour defined to only take type \u2018integer\u2019)  3. Uploaded onto REDCap through the API a. Obtained REDCap API token b. Obtained importing function from previous intake\u2019s git c. Uploaded tables via the API  Security Aspect:  Technical work REDCap / Simulacrum Aspect:  Python was the main programming language that we used. We conducted data preprocessing on the Simulacrum dataset by removing records that are not accurately reflected in the real world (e.g. female patients with prostate cancer, treatments that occurred after death). We also ensured consistent schema for the dataset in order to adhere with the data dictionary defined in REDCap. We had to define repeating instruments in REDCap due to the varying nature of number of treatments or tumours per patient. Finally, we uploaded (to the best of our abilities) the cleaned datasets onto REDCap using the API. However, due to complications caused by uploading via the API we were only able to upload the av tables and some of the sact_outcome_regimen merged table that we created after cleaning the data. Hence, we broke REDCap and it presents the question: \u201cis REDCap the best way to store this information?\u201d. Also, Simulacrum does NOT include location-specific data (the closest is the type of place a patient died, e.g. a hospital or hospice), so a new visualisation dashboard might need to be made if that\u2019s the aim of a future intake.   Security Aspect: We created a Django application to act as an authentication wrapper around an Rshiny app. Thus access is controlled by Django\u2019s authentication layer and users log in via SSO, which we paired Django with mozilla-django-oidc to accomplish. Currently our SSO server is auth0 but the aim is to move to AAF. We have set up the application such that all that would be needed to move to AAF would be to set the environment variables for server address & security key once AAF provides those, as well as doign any configurations that AAF require on their end. The authorisation is achieved by Django creating user sessions with the \u2018users\u2019 from SSO stored in a PostgresSQL database.  Testing was done locally but the application is packaged in docker and can easily be deployed to a correctly configured nectar server that opens the relevant ports.  Currently the embedded application is   Key Links \u2022 Our final presentation \u2022 Our Github repository \u2022 Our technical diary                   BioNix Student Project Interns: Cat Tuong Anh Nguyen, Di Wu, Liam Mclnerney High-Level Domain work During the first few weeks of the project, we learned about the Nix ecosystem and the required bioinformatics knowledge for the software that we are going to wrap into BioNix. In particular, terms like metagenomics or taxonomic classification for Kraken2, or tandem repeats for TRF. All our knowledges are then presented in a meeting on a whiteboard for our supervisors to correct any false interpretation.  The research is then compiled by us to be added into the existing BioNix wiki by WEHI, including any modifications so that the page is more coherent and user-friendly. We added a project introduction page, added some more questions to the FAQ, and had a scan through the existing information to make sure they are non-repetitive, correct, coherent, uniform and change them if necessary Architecture / Algorithm work  We had help from our instructor to visualize what an expression to wrap our software would look like, combined with our learning from both the existing package-base, and our personal research. We understood the basic structure of the expression, and how Kraken2 would require no configuration, because all the configs are already in the GitHub repository, or how TRF require thorough management of its dependencies.  In addition, we understood the contribution steps for nixpkgs and ensure that our expressions abide by the rules. Technical work \u2022 Finalized the expression of wrapping TRF to BioNix. \u2022 Made prototypes of expressions to wrap Kraken2. \u2022 Wrote and tested the prototype expressions for Kraken2.  Key Links \u2022 Fork repo of the wiki \u2022 Trello to manage tasks \u2022 Final Presentation Conference Organiser Student Project   Interns: Zheyuan Wu, Antonio Wang, Wingyee He, Natasha Ngo, Jiaxi Zheng High-Level Domain work The Conference Organiser project aims to streamline the annual RSEAA conference, which fosters inclusivity and recognition for software engineers worldwide. In the second intake, the team focused on two key areas. First, a dynamic HTML page was developed to update key dates on the main website, RSEAA.org.au, enhancing user experience. Second, the team focused on creating a platform that drew inspiration from a popular live polling application called CrowdPurr. Within this polling project, the team was divided among two sub-projects: One focused on extending Claper, an existing open-source live polling tool, while the other group built a custom live polling application from the ground up using React.  Architecture / Algorithm work   Claper architecture:  React Live Polling: High-level Architecture: Database Architecture:   Technical work  Live polling application:   Frontend: React Library (HTML, Javascript, CSS) Backend (Database and functionality):  Testing and integration: NectarVM (used for docking)   Claper:  Frontend: HTML, TailwindCSS Backend: Elixir, Phoenix Testing and integration: NectarVM  Webpage:   Simple HTML, CSS and JavaScript  Key Links  - Live polling react application: https://github.com/ngonatasha/WEHI-Conference-Organiser - RSEAA webpage: https://github.com/ngonatasha/RSEAA.github.io - Project Claper: https://github.com/Jazzzheng9/Claper.git - Original Claper: https://github.com/ClaperCo/Claper - Final presentation: Conference Organiser Final Presentation.pdf - Whiteboard presentation: Conference Organiser Whiteboard presentation.pdf - Technical diary: Technical Diary  Data Commons / REDMANE Data Registry Student Project  Interns: Haoxuan Lu, Jeremy Lau, Natasha Mulay High-Level Domain work The Data Registry is a web-application that connects Raw and Processed Data to the Data Portals such as cBioPortal, Omero, Aquila etc., to form the Data Commons/REDMANE. It has four main components, the front end, the backend, the database and the virtual machine (Nectar). As the Data Registry subgroup, we addressed the frontend, backend and VM as the main areas of work. The frontend involved the creation of different components such as the Projects components which linked to the Patients and Datasets components (Figure 1).  Architecture / Algorithm work   Figure 1. ER diagram of different components within the frontend of the Data Registry and how they link together.  Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. Technical work Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. Key Links Frontend with React (Current): https://github.com/jeremlll/REDMANE_react.js Frontend with React (Base): https://github.com/HxLu03/DataCommons FAST API (Working one): GitHub - jeremlll/REDMANE_fastapi   Data Commons / REDMANE Data Ingestion Student Project Interns: Xinyu Wang, Boyu Chen, Chelsea Kwan, Bucheng Liu High-Level Domain work The aim of the Data Commons Project is to: Allow for ease of access to various datasets for researchers and stakeholders  Ability to locate raw/processed data stored on local servers through links on the data registry  Access summarised data and visualisations on data portals  Form connections between data registry, local servers and external data portals (cBioPortal, Aquila etc.) For the Data Ingestion, the primary goal is to Ensure that datasets are validated and ingested into cBioPortal.  Key responsibilities would include validating datasets using the validator tool, ingesting validated datasets into the cBioPortal system, and setting up and manage the infrastructure for the ingestion process.  Architecture / Algorithm work   Summary Diagram:   Architecture:  Platform Data Workflow     Technical work Setting up the virtual environment: Ubuntu VM Setup:  Create an Ubuntu virtual machine (VM) on the server to run the validator and manage the ingestion process.  Portainer for Docker Management:  Install and use Portainer to manage Docker containers for deploying the ingestion environment.  Key Links Data Ingestion Documentation Data validator repo: https://github.com/Morning-NFX/DataCommons-cBioPortal Example dataset repo: https://github.com/Morning-NFX/DataCommons-dataset  https://github.com/cBioPortal/cbioportal https://docs.cbioportal.org/using-the-dataset-validator/ https://docs.cbioportal.org/file-formats/          Data Commons / REDMANE Authentication Student Project Interns: Trung Ngo, Lucas Speak High-Level Domain work The primary focus of the project was to establish a modern and seamless authentication system to protect sensitive data within a medical research data registry. The data registry is a web application which was concurrently developed by the Data Commons Data registry team. Authentication ensures that only authorized users can access the system, preventing unauthorized access and data misuse. This protection is critical because it safeguards not only WEHI's research interests but also the privacy rights of patients whose medical data is being managed.  The choice of authentication protocols had to align with industry standards and requirements to ensure compliance with security and privacy regulations while supporting Single Sign-On (SSO) for ease of access.  High level work consisted of:  - Researching what resources were available and suitable for this project. - Understanding how different authentication protocols worked, and the advantages/disadvantages of each. - Identifying the requirements of the authentication system. This work resulted in making the following decisions: - OpenID Connect (OIDC) was selected as the primary authentication protocol due to its suitability for research organizations, as recommended by the Australian Access Federation (AAF). OIDC supports both SSO and social login, offers flexibility in integrating different identity providers, and is simpler to implement compared to alternatives like SAML.  - Keycloak, an open-source identity and access management system, was chosen to run on the authentication server. It offers ease of setup, sufficient security for non-critical use cases, and eliminates the licensing costs associated with platforms like Auth0. Keycloak also allows integration with AAF as an identity provider, leveraging OIDC to provide seamless access for Australian researchers. Architecture / Algorithm work  The following diagram depicts the typical authentication sequence for a user signing into the data registry using their Okta credentials:  Technical work Luke: - Researched OIDC and authentication tools. - Discovered, installed and configured Keycloak - Implemented OIDC authentication flow with demo Python script and keycloak. Trung: - Deployed Keycloak with test web application to implement the OIDC authentication protocol.  - Modified Keycloak realm to accept Auth0 as an Identity Provider. - Created and performed authentication demo in final presentation. Key Links Authentication set-up docs: https://wehieduau.sharepoint.com/:f:/r/sites/StudentInternGroupatWEHI/Shared%20Documents/Data%20Commons/2024%20Semester%202/Authentication?csf=1&web=1&e=54AxBl Final presentation (slides): https://wehieduau.sharepoint.com/:p:/s/StudentInternGroupatWEHI/EYQh5qAhApVJjh51r84NQgcBKihFHMF2nj8x3ctK39fQjw?wdOrigin=TEAMS-MAGLEV.null_ns.rwc&wdExp=TEAMS-TREATMENT&wdhostclicktime=1728513382398&web=1 ^OUTDATED OIDC demo python script (rough): https://wehieduau.sharepoint.com/:f:/r/sites/StudentInternGroupatWEHI/Shared%20Documents/Data%20Commons/2024%20Semester%202/Authentication/OIDC%20Python%20demo?csf=1&web=1&e=dlAegm  Genomics Invoicing Student Project Interns: Changyuan Ni, Jiayi, Li, Iffat Azeez, Ramon Felipe High-Level Domain work Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. Architecture / Algorithm work  Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. Technical work Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.   Key Links \u2022  Haemosphere Student Project Interns: Michele Meliala, Lady Feren Pangjaya, Thanh Pham, Thi Hong Minh Dao, Zachary Iskandar  High-Level Domain work Our group\u2019s work was the continuation of the ongoing migration of Haemosphere from Python 2 to Python 3, due to Python 2 no longer being supported. We mainly focused on improving overall speed on the site, and improving the scalability of the site to accommodate multiple simultaneous users without crashing. After extensive testing, we determined that a caching-related approach was the best solution for performance enhancement. In addition, we made minor improvements to the existing tutorials and documentation, so that hopefully future intakes will have a smoother and less confusing onboarding experience.  We implore future intakes to explore this caching solution in greater depth to assess its feasibility, and to debug some datasets such as Schultze and Immgen to make them compatible with the new Python 3 framework, as well as any other necessary improvements to the site to further enhance the user experience. In the longer term, we also recommend Haemosphere to be migrated to a supported version of Python, as support for the destination version (Python 3.6) ceased in December 2021, almost three years ago at the time of writing.  Architecture / Algorithm work We trialled several different solutions and measured the impact each solution had on improving speed and performance. These included increasing the RAM of the virtual machine, pre-loading data onto RAM cache and utilising disk cache. Through performance testing, we found that a large memory virtual machine with caching was the most efficient in terms of speed and reliability. We also explored changing file formats using .h5 and .parquet, but this method was overcomplicated and only yielded minimal improvements compared to other methods.   Technical work Fixed minor bugs that prevented us from running the server (typos, missing dependencies during the onboarding process, tweaks to config files) Took the opportunity to explore the option of a higher memory VM after the hosting arrangement with the University for the publicly accessible version of Haemosphere was changed Conducted performance testing on various differential expression datasets to assess performance and detect errors for future intakes to fix, as well as to compare different server configurations Implemented RAM and disk caching, which significantly improved performance   Key Links \u2022 Haemosphere website \u2022 Public Github repository \u2022 Sharepoint \u2022 YouTube link for presentation (add link when uploaded)   Student Organizer Student Project  Interns: Jiaman(Mandy) Xu, Xiaoqing(Betty) Hu, Yiyang Chen, Yovela Budiman High-Level Domain work The team analyzed the web app's code, setting short, mid, and long-term goals. Short-term tasks, like improving the navigation bar, creating filtered student lists, and updating the public data schema and database, were completed. Mid-term goals, such as linking project and intake pages and refining the UI, are underway. Long-term goals, including database optimization and platform migration, are set for future interns. Documentation in the project wiki and SQL scripts ensure smooth handovers for upcoming cohorts. Architecture / Algorithm work  The project uses a modular architecture, making it easy to test and integrate new features. A responsive navigation bar adapts to different screen sizes, with dropdowns for better organization. Key features include dynamic student lists, email copy functionality, and direct links between project, intake pages, and filtered student lists, streamlining navigation. Technical work \u2022 Frontend (UI/UX): o Designed a responsive navigation bar using HTML and CSS for seamless navigation across devices, incorporating dropdown menus for different sections. o Developed subpages for student lists (current, future, past, all students) and added buttons linking intake and project pages with pre-filtered data. \u2022 Backend (Database & Functionality): o Generated fake test data and updated database schemas accordingly. o Created upgrade_database.sql to document and maintain database changes for future students. \u2022 Testing & Integration: o Tested the system using Nectar VM to simulate real-world user behavior and ensure smooth functionality.  Key Links 1. Link to the wiki:   https://github.com/WEHI-ResearchComputing/student-intern-organiser/wiki 2. Link to the Technical notes:  Technical Notes 2024 S2 3. Link to the Final Presentation slides in SharePoint:                        Genomics Invoicing Project: Interns:  Changyuan (David) Ni, Jiayi (Joyce) Li, Ramon Felipe, Iffat Abdul Azeez High-Level Domain work The team first learns in detail the client\u2019s original workflow, in which the client wishes to have the tedious manual process of producing invoices automated. The team drafted and refined the wireframe for the concept of automation app in generation of genomic invoices. The team considered architectural limitations of the deployment environment and develops software architecture of the app based on the limitations. Architecture / Algorithm work Here is the link to the architecture diagram the team developed:  https://lucid.app/lucidchart/295c39f2-77b2-4cd8-9a64-bced69e188b7/edit?viewport_loc=379%2C407%2C4469%2C2110%2C0_0&invitationId=inv_91729030-3e45-4bcf-aac6-ce3bb4682304 Technical work The team configured and tested the local development environment, server-side deployment environment and the protocol for connecting to the server at WEHI. The team develops an upload interface, with testing files and correct output ready.    Key Links 1. Link to wiki, all relevant links are found in the wiki: Genomics-invoicing wiki \u00b7 Ayacolyte/genomics-invoicing Wiki \u00b7 GitHub   ",
        "topic": "RCP0032 Intake 10 Student Internship Summary Reports",
        "keywords": [
            "data",
            "github",
            "project",
            "technical",
            "work"
        ],
        "source": "RCP0032 Intake 10 Student Internship Summary Reports.pdf"
    },
    {
        "title": "Content from Research Computing Platform Student Internship Handbook",
        "content": "Research\nComputing\nPlatform\nStudent Handbook3\n4\n5\n6\n7\n8Introduction\nPhilosophy\nBenefits for Students\nNumbers behind the program\nCode of Conduct\nWant to know more?Table of ContentsIntroduction\nThe Research Computing Platform (RCP) is a  \ncollaborative, multi-disciplinary lab that\nsupports and advocates for researchers and\ntheir computational research needs at WEHI.\nRCP has established a 100% remote, unpaid\nstudent internship program with subjects\nprovided at the University of Melbourne. We\ndid this to leverage the experience we have in\nthe RCP of working with student software\ninterns by collaborating with labs. \nBecause this is unpaid, we aim to get students  \nvia the official programs at the University of\nMelbourne so they can obtain course credit.\nThis program allows us to share our\nknowledge and experiences with the students\nto help them to build their confidence so thatthey know that they have the skills and\ninitiative to handle future situations.\nThere are three intakes during the year,\nSemester 1, Semester 2, and Summer.\nWe aim to share the information from our\ncurrent student interns to our future student\ninterns. We do this by getting our current\nstudents to document the nuances of the\nproject and the challenges that they faced. \nWe are constantly trying to improve the\nexperience for our students and always\nappreciate feedback.\nWhile our most consistent feedback is to have  \nan in-person work environment, we are only\nproviding 100% online work environments.\nWEHI RCP  Student Handbook | 3Students at RSE Parkville lunch that happens on the second Thursday of each month.Proactive\nProactiveProactive\nProactive\nConcept-first approach\nIt is important for students to\nunderstand the high-level concepts of\nthe domain the student is working in.\nThis increases the independence of\nthe student to work through complexity.\nTest your limits\nThe ability to learn quickly by doing\nyour own research is important.\nFinding out how fast you learn and\nwhere your limits are, in a safe space,\ncan help you to know yourself better.Philosophy\nDocumentation is Key\nStudents need to recognise the limited\ntime they have and what they can\nachieve. This is why documentation is\nkey to ensure information is passed to\nfuture students.\nCollaboration is vital\nThere are multiple internships running\nat the same time. We encourage\nstudents to collaborate within projects\nand across sister projects (similar\nprojects) via co-working meetings.\nWEHI RCP  Student Handbook | 4Benefits for Students\nThere are many benefits for student interns in\nthis program to help them progress in their\ncareers by giving them opportunities to grow\nand learn in a safe environment and achieve\ntheir potential, which builds confidence.\nMany students start the program having some\nlevel of technical skills, but very little\nunderstanding of how important it is to know\nthe nuances and concepts of the work\nenvironment and domain knowledge.\nThis is why we give them the time to research\nthe concepts and give them feedback on how\nto refine those concepts.\nStudent interns are provided with honest\nfeedback to show where their skills and\nabilities place them, what kind of organisation\nthey might be a good fit with, and how they\ncan improve during and after the internship.Students also get the opportunity to learn real-\nworld skills such as keeping meeting notes,\ndocumentation, learning how to communicate,\nand giving presentations. \nStudents also get the opportunity to deal with\nrealistic data and real world problems, where\nthe answers and the technical solution is not\nso clear as in their coursework.\nStudents are encouraged to self-direct during\nthe internship. Balancing what the student\nwants to do and benefiting WEHI is a great\nexample of a fantastic project.\nAll in all, students have the opportunity to\nleave the internship with an improved sense of\nconfidence that they have the ability to handle\nnew environments and domains, even if they\nhaven't worked in that area before. This is the\nbest outcome we can hope for as supervisors.\nWEHI RCP  Student Handbook | 5\nTop L-R: Youran Zhou, Marika Benetti-Hille. Bottom L-R: Rowland Mosbergen, Gilbert Putra.Numbers behind the program\n17\nstudent projects\n104\nstudent interns\n19,000+\nhours of effort4.7/5\nstudent rating\n9\nprojects per intake\n30\nstudents per intake\nWEHI RCP  Student Handbook | 6Code of Conduct\nThis was originally taken from the Code of\nConduct from Django. This is a snippet of the\nfull Code of Conduct on the website.\nThis community is made up of a diverse\nmixture of researchers, research software\nengineers, professionals and students.\nDiversity is what we are hoping to improve our\ncommunities and workplaces, but it can also\nlead to communication issues and\nunhappiness. \nTo that end, we have a few ground rules that\nwe ask people to adhere to. This code applies\nequally to founders, mentors and those\nseeking help and guidance.\nThis isn\u2019t an exhaustive list of things that you\ncan\u2019t do. Rather, take it in the spirit in which\nit\u2019s intended -a guide to make it easier to\nenrich all of us and the technical communities\nin which we participate.\nThis code of conduct applies to all spaces\nmanaged by the group. This includes chat\nrooms, the mailing lists, events, and any other\nforums created by the platform which the\ncommunity uses for communication. \nIn addition, violations of this code outside\nthese spaces may affect a person's ability to\nparticipate within them. If you believe\nsomeone is violating the code of conduct,\nplease let us know.\nThe key points are:\nBe friendly and patient.\nBe welcoming.\nBe considerate.\nBe respectful.\nBe careful with the words you choose.We strive to be a community that welcomes\nand supports people of all backgrounds and\nidentities. This includes, but is not limited to\nmembers of any race, ethnicity, culture,\nnational origin, colour, immigration status,\nsocial and economic class, educational level,\nsex, sexual orientation, gender identity and\nexpression, age, size, family status, political\nbelief, religion, and mental and physical ability.\nYour work will be used by other people, and\nyou in turn will depend on the work of others.\nAny decision you take will affect users and\ncolleagues, and you should take those\nconsequences into account when making\ndecisions. Remember that we\u2019re a diverse\ncommunity, so you might not be\ncommunicating in someone else\u2019s primary\nlanguage.\nNot all of us will agree all the time, but\ndisagreement is no excuse for poor behavior\nand poor manners. We might all experience\nsome frustration now and then, but we cannot\nallow that frustration to turn into a personal\nattack. It\u2019s important to remember that a\ncommunity where people feel uncomfortable\nor threatened is not a productive one.\nMembers of the community should be\nrespectful when dealing with other members\nas well as with people outside the community.\nWhen we disagree, try to understand why.\nDisagreements, both social and technical,\nhappen all the time and we are no exception. It\nis important that we resolve disagreements\nand differing views constructively. Remember\nthat we\u2019re different. The strength of this\ncommunity comes from its diversity. Different\npeople have different perspectives on issues.\nBeing unable to understand why someone\nholds a viewpoint doesn\u2019t mean that they\u2019re\nwrong. \nWEHI RCP  Student Handbook | 7Want to know more?\nAll the information on this page is on the\nwebsite\u2019s main student page via the QR code\ndown below.\nFAQ\nThere is a FAQ on the website under \u201cKey\nDocuments to review and FAQ\u201d.\nThis FAQ provides information on:\nApplying for the internship program,\nOnboarding onto the program,\nWhat is expected at meetings, and\nWhat is expected when you finish.\nKey Milestones and Emails\nThe Key Milestones and Emails page can be\nfound under \u201cKey Documents to review and\nFAQ\u201d.\nAt the bottom fo the Key Milestones and\nEmails page you can find the onboarding\nemails that are sent out throughout the intake\nto remind students of the expectations of the\nprogram.\nLearn real world skills\nWe prepare students for the real-world by\nteaching them:\nhow understanding the domain problem\nand the users is more important than\ntechnical skills, and how to work on a\ncomplex, ambiguous project,\nshowing them how to become as\nindependent as possible,\nshow them how to document and share\nknowledge to others in a professional\nmanner,\nexplain how a software maturity model can\nhelp clarify expectations, and\nteaching them how to work productively in\na remote environment.We even tell students how to try to avoid the\ntop 5 mistakes that students make.\nAvailable Projects\nThere is a list of available projects under the\ntitle \u201cList of student intern projects\u201d.\nThese projects change from intake to intake,\nso please reach out if you are unsure via\nemail:  mosbergen [dot] r [at] wehi [dot] edu\n[dot] au.\nHow to Apply\nWe suggest that you write a 1 page cover\nletter introducing yourself, along with your\nresume. You can find more details under \u201cHow\nto Apply\u201d.\nThis is a popular program as we can get over\n60 applications per intake for only 30 student\nplaces. This is why it can be challenging to\naccomodate all students. We do try our best to\nprovide feedback but this is limited due to the\nnumbers involved.\nWEHI RCP  Student Handbook | 8Research\nComputing\nPlatform",
        "topic": "Research Computing Platform Student Internship Handbook",
        "keywords": [
            "program",
            "projects",
            "rcp",
            "student",
            "students"
        ],
        "source": "Research Computing Platform Student Internship Handbook.pdf"
    },
    {
        "title": "Content from Student Projects Outline - Summer 2425",
        "content": "Student Projects Outline - Summer 24/25  \n \nIntroduction  \n \nPlease remember these are long -term goals and this internship is a best effort internship. This \nmeans that I am not expecting any of these goals to be completed. I am simply expecting that \nwe're going to do the best that we can, collaboratively.  \n \nWhat I want from you is to be able to take these cryptic notes, watch the final presentations,  and \nuse them to  understand what you might want to do as part of this internship  (see below) . \n \n \n \nKey Links  \nPlease bookmark these key links:  \n\u2022 the Welcome Slides for more general information,  \n\u2022 FAQs to help you troubleshoot problems , \n\u2022 the Student Internship Handbook , \n\u2022 Student Projects Outline  to help explain high level context and tasks,  \n\u2022 the previous summary report from semester 2 2024 , \n\u2022 the Sharepoint from previous intakes that is tied to WEHI -wide student intern group , \n\u2022 you can connect to your team mates, sister projects and skills register.  \n \n \nHigh level context to help with Stage 1  \n \nTo find out more about the projects please look at the information below:  \n \n1. Introduction to REDMANE (slides by Rowland)*  \na. Create synthetic multi -omics data  to match synthetic clinical and other metadata  \nb. Extend functionality of the Data Registry application  in ReactJS and FASTAPI  \nc. Ingestion of data and metadata into the Data Registry using authentication  \nd. Setup authentication for multiple Data Portals  using OIDC, AAF, and KeyCloak  \ne. Setup cBioPortal as a Data Portal  on the Nectar Research Cloud  \nf. Setup generic secure Shiny/R App  as a Data Portal on the Nectar Research \nCloud  \ng. Setup Omero as a Data Portal on the Nectar Research Cloud  \nh. Setup Storage Calculator  as a Data Portal on the Nectar Research Cloud  \ni. Identify other Data Portals for key data types  \n2. Clinical Dashboards  \na. Create synthetic multi -omics data  to match synthetic clinical and other metadata  \nb. Setup generic secure Shiny/R App  as a Data Portal on the Nectar Research \nCloud  \n3. Student Organiser   \na. Create a way to review resumes quickly  \nb. How can we search through all help documents using RAG LLM?  \nc. Create new views for \"Allocation\" and \"Review resume\" versus \"interview\"  \n \n* for more information on REDMANE please access the General REDMANE FAQ.  \nHigh level  tasks to help build context for Stage 2  \n \nPlease review these and ask lots of questions in weeks 1 and 2. We want you to understand \nwhy and make suggestions to improve these potential tasks.  Asking questions is really \nimportant to ensure you understand why you are doing things!  \n \nProject/Subpr\noject  Bluesky Tasks (not feasible)  REDMANE \nDemo and \nQuality team  \u2022 Setup a permanent demo  \no Data registry with SSL  \no Using synthetic datasets that are stored in data portals:  \n\u25aa Clinical data (WEHI REDCap)  \n\u25aa WGS data (cBioPortal)  \n\u25aa Imaging (Omero)  \n\u25aa Spatial Omics (?)  \no Two organisations (VM) to \u201cstore\u201d large raw synthetic data \nlinked to the other data portals  \n\u2022 Provide Quality Control and first level support to other groups, \nincluding how do you get your code into the demo environment.   \n\u2022 Discuss and draft what is needed for a Data Portal to be accepted \ninto the \u201cApp store\u201d:  \no Has to be dockerized  \no OICD authentication  \no Per dataset authorisation for users and groups  \no Open Source  \no Ability to link back to Data Registry  \no Create empty templates for Django, Flask, Ruby on Rails etc \nthat are ready to be part of the REDMANE ecosystem and \ncan be built on top of easily  \nREDMANE \nData Portals  \u2022 Setup Omero as a Data Portal  \n\u2022 Create synthetic data for imaging or special omics that is tied to \nclinical data and put it into Omero  \n\u2022 Document setup of the system (if needed)  \n\u2022 Work with the Demo and Quality team to classify if Omero  is ready \nto be a data portal  \n\u2022 Setup authentication to be in sync with data registry and cBioPortal  \nREDMANE \nWeb Dev  \u2022 Work on adding more functionality to the data registry based on the \nwireframes  \n\u2022 Add in authentication and authorization into the data registry  \n\u2022 Help the demo and quality team identify what is the definition of a \ndata portal that can work within this ecosystem  \n\u2022 Work with the data integration team to provide an API with \nauthentication  \n\u2022 Review the wireframes in the presentation and identify new pages if \nnecessary  \n\u2022 Set up unit tests as well as functional tests to ensure functionality is \nnot lost  \u2022 Work with the demo and quality team to provide pull requests so that \nnew functionality can be added to the demo environment  \n\u2022 Work with the data integration team to demo how and update from \nan organization who is just received new files would look like  \n\u2022 Discuss with the PDF coding team how you would integrate the \nfunctionality into the data registry  \n\u2022 UI to add in metadata at scale like Stemformatics and tie in \nontologies to ensure metadata is consistent  \nREDMANE \nWorkflows  \u2022 Set up one or two basic workflows using synthetic or public data \nsuch as whole genome sequencing or single cell rnaseq.  \n\u2022 Tie the synthetic data to clinical data along with the clinical \ndashboards team.  \n\u2022 Run this workflow on Milton hpc, possibly using next flow.  \n\u2022 Work with the data registry team to see if they can kickstart a \nworkflow on Milton using information within the data registry for \nthings like input data and where should the output data should go  \n\u2022 Work with the clinical dashboards team to create tutorials of less \nthan 20 slides to explain to a new audience the nuances of the data \nset types  \n \nClinical \nDashboards \nSynthetic Data  \u2022 Create synthetic clinical data within red cap that ties in with data that \nmight already be available in a data portal for example cBioportal  \n\u2022 Create or find public data that could be used to mimic multi -omics \ndata that is tired to the clinical data for example they would have the \nsame sample IDs in the file name of the omics data  \n\u2022 Work with the data ingestion team to ensure that they understand \nthe nuances of the data sets  \n\u2022 Simile work with the workflow team to ensure everyone understands \nthe nuances of the data sets being created  \n\u2022 Work with the workflow team to create tutorials of less than 20 slides \nto explain to a new audience the nuances of the data set types  \nREDMANE \nData Ingestion  \u2022 Create scripts for different operating systems to ingest data into the \ndata registry  \n\u2022 These scripts should create intermediate files to help someone verify \nthe quality and accuracy of the information that is going to be sent to \nthe data registry. This would include a machine readable and a \nhuman readable version of the information such as r o crate  \u2022 These scripts need to hav e some level of authentication to ensure \nthat we keep the information private and secure  \n\u2022 This team should be working with the clinical dashboards team and \nthe workflows team to understand the nuances of the files within \neach data type   \nREDMANE \nCapacity \nPlanning  \u2022 Storage Calculator to calculate future storage needs based on \nprevious numbers  \n\u2022 Work with the REDMANE Data Ingestion team to get numbers and \npossibly will need longitudinal (time series numbers)  \n\u2022 Look at time series databases  \n\u2022 Look at the previous Storage Calculator and use as a basis  \n\u2022 Select two points on a time graph and calculate the extended linear \nregression of those two points  \n\u2022 Calculate and update storage numbers to get better potential costs \nof storage in the future.  \nStudent \nOrganiser Data \nViz \u2022 I need to filter specific views of data across the application. I need a \nper intake view that shows either all students who applied or only \nstudents who finished. I would also like to see a list of students who \nworked on a project in past intakes or for a specific intake  \n\u2022 In a similar vein I would like to calculate some of the numbers for \neach of these specific filtered students such as how many total hours \nwould the student organizer from intake 6 have and what are the \nnames of the students in that intake for that project  \n\u2022 I would also like to visualize the numbers and other dashboard views \nin a more graphical format and some over time as well  \n\u2022 I would also like to build more information into the allocation screen \nwhere I'm assigning students into projects so that I get a better \nunderstanding of the skill set within a team and the hours within a \nteam  \n\u2022 I would also like to improve on the synthetic data set so that it can be \nused to test all the scenarios that the web application can do  \nStudent \nOrganiser PDF \ncoding  \u2022 I want to be able to streamline reviewing a resume and cover letter \nthat is in a PDF form  \n\u2022 I want to be able to highlight a sentence or a paragraph and add a \ncomment. This is the functionality that you can get inside Google \nDrive when you have a PDF.  \u2022 I want to extend this functionality so that not only can I highlight text \ncreate a comment but I also can add one or more tags predefined \ntags about that comment. For example I might highlight a paragraph \nand in my comment I would say this shows excellent communication \nskills and then I would add a tag to that comment called \ncommunication  \n\u2022 I couldn Sport the highlighted text the comments amate and any text \nit at side of that application and stored in the student application as a \nsummary  \n\u2022 I could then access this summary of a person through the allocations \npage when I'm trying to assign students to projects  \nStudent Organiser \nRAG LLM / \nOnboarding  \u2022 I want students to be able to easily search through all the \ndocumentation I have provided on the website and on documents I \nstore in fig share.  \n\u2022 I especially want them to be able to do a search using an LLM and \nreturn accurate data in the form of a link and associated information  \n\u2022 I want to review how we setup the documentation so that it is easy to \nadd documentation into the LLM and it is easy to link to specific \nquestions if needed.  \n\u2022 I also want to review how we onboard students to get them up to \nspeed for the high -level context (stage 1) and the architectural and \nalgorithmic limitations and suggestions (stage 2) so we can move the \n\u201cwhiteboard presentation\u201d from week 4 to week 2 or 3.  \nQuantum \nComputing  \u2022 Reflect on how you like to learn, based on the idea of andragogy, the \nidea of self -directed learning as an adult  \n\u2022 Look at the wiki and the roadmap and decide how you want to learn \nQuantum Computing and what you would like to get out of it  \n\u2022 Create an individual plan for yourself and share with your team \nmates  \n\u2022 Ensure you document your individual plan along the way  \n\u2022 Update the wiki to share an updated version of your plan to help \nothers in the future  \n \nIntake 10 Summary Report  \n RCP#0032 Intake 10 Student Internship Summary reports.docx   ",
        "topic": "Student Projects Outline - Summer 2425",
        "keywords": [
            "create",
            "data",
            "synthetic",
            "team",
            "work"
        ],
        "source": "Student Projects Outline - Summer 2425.pdf"
    }
]